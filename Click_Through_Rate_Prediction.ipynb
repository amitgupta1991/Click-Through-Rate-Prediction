{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                  # Mathetimatical Operations\n",
    "import pandas as pd                 # Data manipulation\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     # Used for plotting graphs.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA COLLECTION\n",
    "\n",
    "df = pd.read_csv('C:/Users/Amit Gupta/Desktop/TP/Code/Apply_Rate_2019.csv')\n",
    "df.head() # shows top 5 rows\n",
    "print('Total number of observations in the dataset are:',df.shape[0]) # Shape() function returns the dimensions of the array. \n",
    "df.info() # Gives the structure of the data w.r.t. different columns.\n",
    "df.drop(['apply'],axis=1).describe() # Level 1 is used to delete the column named 'apply'. Describe() is used for getting the statistical information about the field/column.\n",
    "df['job_age_days'].describe()\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution for classes who applied and did not apply\n",
    "\n",
    "count_classes = pd.value_counts(df['apply'], sort = True)  # This gives the different set of values that the column 'apply' can take. Also, it plots the graph to show the counts of rows having both the values.\n",
    "count_classes.plot(kind = 'bar')\n",
    "plt.title(\"Apply Rate\")\n",
    "plt.xticks(range(2))\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\");\n",
    "\n",
    "print('Count of number of customers who didnt apply:',df['apply'].value_counts()[0])\n",
    "print('Count of number of customers who applied:',df['apply'].value_counts()[1])\n",
    "print('Percentage of apply to non apply as per the data',df['apply'].value_counts()[0]/df['apply'].value_counts()[1],'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the correlation between the features\n",
    "f, ax = plt.subplots(figsize=(12, 10))\n",
    "corr = df.corr()\n",
    "hm = sns.heatmap(round(corr,2), annot=True, ax=ax, cmap=\"Reds\",fmt='.2f',\n",
    "linewidths=.05)\n",
    "f.subplots_adjust(top=0.93)\n",
    "t= f.suptitle('Click Through Rate Variable Correlation Heatmap', fontsize=14)\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = df.corr().where(np.triu(np.ones(df.corr().shape), k=1).astype(np.bool))\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.50)]\n",
    "df.drop(df[to_drop], axis=1)\n",
    "df = df.drop(df[to_drop], axis=1)\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plot for the variables\n",
    "\n",
    "l = ['title_proximity_tfidf', 'description_proximity_tfidf',\n",
    "       'query_jl_score', 'query_title_score',\n",
    "       'city_match', 'job_age_days']\n",
    "for i in range(0,len(l)):\n",
    "    ax = sns.boxplot(df[l[i]],data = df)\n",
    "    plt.show() \n",
    "    \n",
    "# Checking the distribution\n",
    "\n",
    "for feature in df.columns[:-3]: # Plotting the values for various columns with respect to whether they have applied or not.\n",
    "    ax = plt.subplot()\n",
    "    sns.distplot(df[df['apply'] == 1][feature], bins=50, label='Anormal(Apply=1)')\n",
    "    sns.distplot(df[df['apply'] == 0][feature], bins=50, label='Normal(Apply=0)')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title('histogram of feature: ' + str(feature))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "df.skew(axis = 0, skipna = True) \n",
    "df.kurtosis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA CLEANING\n",
    "    \n",
    "print(df.shape) # Gives the dimension of the dataset.\n",
    "df = df.drop_duplicates(keep = 'first') # Considers first value as unique and all the other similar values as duplicate.\n",
    "df.shape \n",
    "# df.isnull().sum() # Getting the number of null values in all the columns.\n",
    "print(\"The number of null values for the all the columns in df are:\")\n",
    "df.iloc[:,0:len(df.columns)].isnull().sum() # Getting the number of null values in all the columns.\n",
    "\n",
    "# Columns with null values are title_proximity_tfidf, description_proximity_tfidf, city_match\n",
    "mean_title_proxmity_tfidf = df['title_proximity_tfidf'].mean()\n",
    "mean_title_proxmity_tfidf\n",
    "mean_description_proxmity_tfidf = df['description_proximity_tfidf'].mean()\n",
    "mean_description_proxmity_tfidf\n",
    "df['city_match'].value_counts()\n",
    "t1 = df['city_match'].value_counts()[0]\n",
    "t2 = df['city_match'].value_counts()[1]\n",
    "if t1>t2:\n",
    "    city_match_imputed_value = 0\n",
    "elif t1<t2:\n",
    "    city_match_imputed_value = 1\n",
    "city_match_imputed_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Value Detection and Treatment\n",
    "\n",
    "# Way-1\n",
    "df['title_proximity_tfidf']=df['title_proximity_tfidf'].fillna(mean_title_proxmity_tfidf)\n",
    "df.iloc[:,0:len(df.columns)].isnull().sum() # Getting the number of null values in all the columns.\n",
    "df['description_proximity_tfidf']=df['description_proximity_tfidf'].fillna(mean_description_proxmity_tfidf)\n",
    "df.iloc[:,0:len(df.columns)].isnull().sum() # Getting the number of null values in all the columns.\n",
    "df['city_match']=df['city_match'].fillna(city_match_imputed_value)\n",
    "df.iloc[:,0:len(df.columns)].isnull().sum() # Getting the number of null values in all the columns.\n",
    "\n",
    "# Way-2\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(df)\n",
    "df= imp.transform(df)\n",
    "#This will look for all columns where we have NaN value and replace the NaN value with specified test statistic. \n",
    "\n",
    "#Other Ways to treat null values\n",
    "# Missing value treatment by removing all the rows having missing values\n",
    "# Copying the dataframe\n",
    "df1=df\n",
    "# drop rows with missing values\n",
    "df1.dropna(inplace=True)\n",
    "# summarize the number of rows and columns in the dataset\n",
    "print(df1.shape)\n",
    "df1.iloc[0:10,0]\n",
    "\n",
    "# Missing value treatment using Imputation:\n",
    "df2=df\n",
    "# count the number of NaN values in each column\n",
    "print(df2.isnull().sum())\n",
    "# fill missing values with mean column values\n",
    "df2.fillna(df2.mean(), inplace=True)\n",
    "# count the number of NaN values in each column after replacing NaN values\n",
    "print(df2.isnull().sum())\n",
    "\n",
    "# Using Imputer class to treat missing values\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "df3=df\n",
    "df3.columns\n",
    "# split dataset into inputs and outputs\n",
    "values = df3.values\n",
    "X = values[:,0:6]\n",
    "y = values[:,6]\n",
    "# fill missing values with mean column values\n",
    "imputer = Imputer()\n",
    "transformed_X = imputer.fit_transform(X)\n",
    "len(transformed_X)\n",
    "for i in range(len(X[4])):\n",
    "    if(X[i,4] > 0.5 and X[i,4] < 1):\n",
    "        X[i,4]=1\n",
    "    else:\n",
    "        X[i,4]=0\n",
    "\n",
    "for i in range(len(X[5])):\n",
    "    if(X[i,5] > 0.5 and X[i,5] < 1):\n",
    "        X[i,5]=1\n",
    "    else:\n",
    "        X[i,5]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Treatment\n",
    "        \n",
    "# Getting all col names\n",
    "col_names = []\n",
    "for col in df.columns: \n",
    "    col_names.append(col)\n",
    "col_names\n",
    "\n",
    "q1_list = []\n",
    "q3_list = []\n",
    "min_list =[]\n",
    "max_list = []\n",
    "\n",
    "# Finding the oth, 25th, 75th, 100th percentile for all the columns\n",
    "a= len(df.columns)-3\n",
    "for i in range(a):\n",
    "    min_list.append(df[col_names[i]].describe()[3])\n",
    "    q1_list.append(df[col_names[i]].describe()[4])\n",
    "    q3_list.append(df[col_names[i]].describe()[6])\n",
    "    max_list.append(df[col_names[i]].describe()[6])\n",
    "min_list\n",
    "q1_list\n",
    "q3_list\n",
    "max_list\n",
    "\n",
    "# Finding the IQR for all columns\n",
    "iqr = []\n",
    "for i in range(len(df.columns)-3):\n",
    "    iqr.append(q3_list[i]-q1_list[i])\n",
    "iqr    \n",
    "\n",
    "# Finding the min and max range of values for all columns and storing them in a list\n",
    "min_value_cols = []\n",
    "max_value_cols = []\n",
    "for i in range(len(df.columns)-3):\n",
    "    min_value_cols.append(q1_list[i]-1.5*iqr[i])\n",
    "    max_value_cols.append(q3_list[i]+1.5*iqr[i])\n",
    "min_value_cols\n",
    "max_value_cols\n",
    "\n",
    "# Replacing outlier values with boundary values\n",
    "temp = len(df.columns[:-3])\n",
    "temp\n",
    "x=0\n",
    "y=0\n",
    "z=0\n",
    "for i in range(len(df)):\n",
    "    print(1)\n",
    "    z=0\n",
    "    for j in range(temp):\n",
    "        print(2)\n",
    "        if(df.iloc[i,j] < min_value_cols[z]):\n",
    "            print(3)\n",
    "            df.iloc[i,j] = min_value_cols[z]\n",
    "            x = x+1\n",
    "            y = y+1\n",
    "            z = z+1\n",
    "        elif(df.iloc[i,j] > max_value_cols[z]):\n",
    "            print(4)\n",
    "            df.iloc[i,j] = max_value_cols[z]\n",
    "            x = x+1\n",
    "            y = y+1\n",
    "            z=z+1\n",
    "        else:\n",
    "            print(5)\n",
    "            x = x+1\n",
    "            y = y+1\n",
    "            z=z+1\n",
    "    \n",
    "# Storing the updated data in excel\n",
    "df.to_csv(r'C:\\Users\\Amit Gupta\\Desktop\\TP\\Code\\Null_Outlier_Treated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation for all the columns which are not normally distributed.\n",
    "\n",
    "df_temp = np.log(df[['title_proximity_tfidf', 'description_proximity_tfidf','query_jl_score', 'query_title_score','city_match', 'job_age_days']])\n",
    "df_temp.head()\n",
    "# Log Transformed Data Stored\n",
    "df.to_csv(r'C:\\Users\\Amit Gupta\\Desktop\\TP\\Code\\Log_Transformed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELLING\n",
    "\n",
    "# Splitting the dataset into training and testing\n",
    "\n",
    "# Splitting the dataset by date\n",
    "train = df.loc[df['search_date_pacific']<'2018-01-27']\n",
    "test = df.loc[df['search_date_pacific'] == '2018-01-27']\n",
    "\n",
    "# Drop the unnecessary columns\n",
    "train.drop(['search_date_pacific','class_id'],axis=1,inplace = True)\n",
    "test.drop(['search_date_pacific','class_id'],axis=1,inplace = True)\n",
    "\n",
    "# Drop irrelevant features\n",
    "X = df.drop(['search_date_pacific','class_id','apply'],axis=1)\n",
    "y = df['apply']\n",
    "\n",
    "# Reset the index\n",
    "X = X.reset_index(drop='index')\n",
    "y = y.reset_index(drop='index')\n",
    "\n",
    "X_train = train.drop(['apply'],axis=1)\n",
    "y_train = train['apply']\n",
    "X_test = test.drop(['apply'],axis=1)\n",
    "y_test = test['apply']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which will be used to get the important parameters like AUC, Classification report\n",
    "\n",
    "def report(test_set, predictions,labels,title):\n",
    "    print('F1 score is:', f1_score(test_set,predictions))\n",
    "    print(\"AUC-ROC is: %3.2f\" % (roc_auc_score(test_set, predictions)))\n",
    "    plot_confusion_matrix(confusion_matrix(test_set, predictions),labels,title)\n",
    "    \n",
    "    #plot the curve\n",
    "    fpr, tpr, threshold = roc_curve(test_set,predictions)\n",
    "    auc = roc_auc_score(test_set,predictions)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.set_title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b',label='Model - AUC = %0.3f'% auc)\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--', label='Chance')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([-0.1,1.0])\n",
    "    ax.set_ylim([-0.1,1.01])\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "#labels = ['No Apply', 'Apply']\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "model = lgb.LGBMClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "#labels = ['No Apply', 'Apply']\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=20)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "accuracy_score(y_test, y_pred.round(), normalize=False)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
